{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# Function to visualize detections (modifying it to accept frame input)\n",
    "def visualize_detections(frame, detections, output_dir, original_width, original_height, confidence_threshold=0.7, class_names=None):\n",
    "    # Convert BGR to RGB for visualization\n",
    "    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process detections\n",
    "    boxes = detections[0]['boxes'].cpu().numpy()  # Bounding boxes\n",
    "    labels = detections[0]['labels'].cpu().numpy()  # Class labels\n",
    "    scores = detections[0]['scores'].cpu().numpy()  # Confidence scores\n",
    "\n",
    "    # Calculate the scaling factors\n",
    "    scale_x = original_width / 800\n",
    "    scale_y = original_height / 800\n",
    "\n",
    "    class_counts = 0\n",
    "\n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        if score >= confidence_threshold:\n",
    "            # Scale the box coordinates back to the original image size\n",
    "            x1, y1, x2, y2 = box\n",
    "            x1, y1, x2, y2 = int(x1 * scale_x), int(y1 * scale_y), int(x2 * scale_x), int(y2 * scale_y)\n",
    "\n",
    "            if x1 >= 0 and y1 >= 0 and x2 <= image_rgb.shape[1] and y2 <= image_rgb.shape[0]:\n",
    "                # Draw the bounding box on the original image\n",
    "                cv2.rectangle(image_rgb, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            \n",
    "            # Get the class label for the current object\n",
    "            # label_text = class_names[label] if label > 0 and class_names else f\"Class {label}\"\n",
    "\n",
    "            # # Add label and score text above the bounding box\n",
    "            # text = f\"{label_text} ({score:.2f})\"\n",
    "            text = f\"({score:.2f})\"\n",
    "            class_counts += 1\n",
    "            \n",
    "            # Put text above the bounding box\n",
    "            cv2.putText(image_rgb, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Save the image to the output directory\n",
    "    output_path = os.path.join(output_dir, f\"detected_{time.time()}.jpg\")\n",
    "    cv2.imwrite(output_path, cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)) \n",
    "    print(f\"Saved processed image: {output_path}\")\n",
    "\n",
    "    return class_counts\n",
    "\n",
    "# Load Faster R-CNN model\n",
    "def fasterrcnn_resnet50_fpn_v2():\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn_v2(weights=torchvision.models.detection.FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT)\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    model.to(device)  # Move the model to the specified device (CPU or GPU)\n",
    "    return model\n",
    "\n",
    "# Prepare the model and directories\n",
    "def loading_model():\n",
    "    model_detection = fasterrcnn_resnet50_fpn_v2()\n",
    "    output_dir = os.path.join(\"detections\", \"fasterrcnn_resnet50_fpn_v2\")\n",
    "    csv_file_path = os.path.join(\"testing\", \"fasterrcnn_resnet50_fpn_v2.csv\")\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    csv_dir = os.path.dirname(csv_file_path)\n",
    "    os.makedirs(csv_dir, exist_ok=True)\n",
    "    \n",
    "    return model_detection, output_dir, csv_file_path\n",
    "\n",
    "# Set the device to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Preprocessing: Resize the image and normalize it\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),  # Convert the image to a tensor\n",
    "    torchvision.transforms.Resize((800, 800), antialias=True),  # Resize to a fixed size\n",
    "])\n",
    "\n",
    "# Initialize RTSP stream\n",
    "feed1 = cv2.VideoCapture(\"rtsp://10.64.83.237:8554/video_stream\")\n",
    "\n",
    "# Ensure the feed is opened\n",
    "if not feed1.isOpened():\n",
    "    print(\"Failed to open RTSP stream.\")\n",
    "    exit()\n",
    "\n",
    "model_detection, output_dir, csv_file_path = loading_model()\n",
    "\n",
    "\n",
    "# Open the CSV file for writing\n",
    "with open(csv_file_path, mode='w', newline='') as csv_file:\n",
    "    fieldnames = ['id','Image Name', 'Total Time (s)', 'Preprocessing Time (s)',\n",
    "                  'Detection Time (s)', 'Post-processing Time (s)', 'Items Detected']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames = fieldnames)\n",
    "\n",
    "    writer.writeheader()  # Write the header only once\n",
    "    \n",
    "    image_count = 0\n",
    "    while feed1.isOpened():\n",
    "        ret, frame = feed1.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to read frame from RTSP stream.\")\n",
    "            break\n",
    "        \n",
    "        # Display grey-filtered videos\n",
    "        grey1 = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imshow(\"RealSense\", grey1)\n",
    "\n",
    "        image_name = f\"frame_{image_count}\"\n",
    "        image_count += 1\n",
    "\n",
    "        total_start_time = time.perf_counter()\n",
    "\n",
    "        # Start preprocessing time\n",
    "        preprocessing_start_time = time.perf_counter()\n",
    "        \n",
    "        original_height, original_width = frame.shape[:2]\n",
    "        \n",
    "        # Convert frame to PIL Image\n",
    "        image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # Transform the image for detection\n",
    "        img_tensor = transform(image).to(device)\n",
    "        img_tensor = img_tensor.unsqueeze(0)\n",
    "\n",
    "        # End preprocessing time\n",
    "        preprocessing_end_time = time.perf_counter()\n",
    "        preprocessing_time = preprocessing_end_time - preprocessing_start_time\n",
    "\n",
    "        # Start detection time\n",
    "        detection_start_time = time.perf_counter()\n",
    "\n",
    "        # Perform detection\n",
    "        with torch.no_grad():\n",
    "            detections = model_detection(img_tensor)\n",
    "\n",
    "        # End detection time\n",
    "        detection_end_time = time.perf_counter()\n",
    "        detection_time = detection_end_time - detection_start_time\n",
    "\n",
    "        # Post-processing detections\n",
    "        postprocessing_start_time = time.perf_counter()\n",
    "\n",
    "        total_detections = visualize_detections(frame, detections, output_dir, original_width, original_height)\n",
    "\n",
    "        postprocessing_end_time = time.perf_counter()\n",
    "        postprocessing_time = postprocessing_end_time - postprocessing_start_time\n",
    "\n",
    "        # Calculate total time\n",
    "        total_end_time = time.perf_counter()\n",
    "        total_time = total_end_time - total_start_time\n",
    "\n",
    "        # Write the row to the CSV file\n",
    "        row = {\n",
    "            'id': image_count,\n",
    "            'Image Name': image_name,\n",
    "            'Total Time (s)': total_time,\n",
    "            'Preprocessing Time (s)': preprocessing_time,\n",
    "            'Detection Time (s)': detection_time,\n",
    "            'Post-processing Time (s)': postprocessing_time,\n",
    "            'Items Detected': total_detections\n",
    "        }\n",
    "\n",
    "        writer.writerow(row)\n",
    "\n",
    "        print(f\"Processed frame {image_count}, saved results to CSV.\")\n",
    "\n",
    "        # Display the frame (optional)\n",
    "        cv2.imshow(\"Detected Frame\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release the feed and close windows\n",
    "feed1.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
